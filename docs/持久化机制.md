# 持久化机制

hdp(Hard disk persistence) 是通过 aof(append only file) 和 snapshot 共同实现的

持久化的粒度是以 slot 为粒度的

当 aof 条数 达到指定数量时候，会开始进行一次 snapshot 压缩, 然后重新创建 aof 文件

## 执行 bg_save

1. 遍历每一个 slot，依次执行

   1. 加锁 slot 禁止 修改 继续写入
   1. 调整 hdp 的新文件名，base id
   1. 调整 aof 的 cur_id = base_id
      - aof 每次都会判断 cur_id,所以调整后，aof 的逻辑会自动调整
   1. 解锁 （锁定的时间只是调整了两个变量，特别短）
   1. fork 子进程
      - 主进程返回
      - 子进程写 snapshot, 写完之后清理上一次的文件（snapshot 和 aof）

1. aof 的每次执行

   1. 消费 forward
   1. 如果 forward 来的 id
      - `<= cur_id`, 忽略
      - `== cur_id + 1`, 写入
      - `> cur_id + 1` 去 forward 缓存中寻找， 并补上落下的部分，
        - 如果找不到就打 error log (临时处理方案), 找不到的可能性很小
